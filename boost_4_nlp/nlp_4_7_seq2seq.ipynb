{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advanced-marshall",
   "metadata": {},
   "source": [
    "# Seq2Seq\n",
    "\n",
    "1. Encoder 구현\n",
    "2. Decoder 구현\n",
    "3. Seq2Seq 모델을 구축하고 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-attention",
   "metadata": {},
   "source": [
    " ## 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proprietary-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-chicken",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "`src_data` 를 `trg_data` 로 바꾸는 task를 수행하기 위한 sample data 입니다.  \n",
    "전체 단어수는 100개이고 다음과 같이 pad_token, start_token, end_token의 id도 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extensive-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "pad_id = 0\n",
    "sos_id = 1\n",
    "eos_id = 2\n",
    "\n",
    "src_data = [\n",
    "  [3, 77, 56, 26, 3, 55, 12, 36, 31],\n",
    "  [58, 20, 65, 46, 26, 10, 76, 44],\n",
    "  [58, 17, 8],\n",
    "  [59],\n",
    "  [29, 3, 52, 74, 73, 51, 39, 75, 19],\n",
    "  [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93],\n",
    "  [39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99, 5],\n",
    "  [75, 34, 17, 3, 86, 88],\n",
    "  [63, 39, 5, 35, 67, 56, 68, 89, 55, 66],\n",
    "  [12, 40, 69, 39, 49]\n",
    "]\n",
    "\n",
    "trg_data = [\n",
    "  [75, 13, 22, 77, 89, 21, 13, 86, 95],\n",
    "  [79, 14, 91, 41, 32, 79, 88, 34, 8, 68, 32, 77, 58, 7, 9, 87],\n",
    "  [85, 8, 50, 30],\n",
    "  [47, 30],\n",
    "  [8, 85, 87, 77, 47, 21, 23, 98, 83, 4, 47, 97, 40, 43, 70, 8, 65, 71, 69, 88],\n",
    "  [32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18],\n",
    "  [37, 14, 49, 24, 93, 37, 54, 51, 39, 84],\n",
    "  [16, 98, 68, 57, 55, 46, 66, 85, 18],\n",
    "  [20, 70, 14, 6, 58, 90, 30, 17, 91, 18, 90],\n",
    "  [37, 93, 98, 13, 45, 28, 89, 72, 70]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-spread",
   "metadata": {},
   "source": [
    "각각의 데이터를 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serial-omega",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 113975.65it/s]\n"
     ]
    }
   ],
   "source": [
    "trg_data = [[sos_id] + seq + [eos_id] for seq in tqdm(trg_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "upper-testimony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 75, 13, 22, 77, 89, 21, 13, 86, 95, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lightweight-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data, is_src=True):\n",
    "    max_len = len(max(data, key = len))\n",
    "    print(f\"Maximum sequence length: {max_len}\")\n",
    "    \n",
    "    valid_lens = []\n",
    "    for i, seq in enumerate(tqdm(data)):\n",
    "        valid_lens.append(len(seq))\n",
    "        if len(seq) < max_len:\n",
    "            data[i] = seq + [pad_id] * (max_len - len(seq))\n",
    "            \n",
    "    return data, valid_lens, max_len\n",
    "    # 패딩된 데이터, 각 원본 길이(to torch..pack_padded.), 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "integrated-postcard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 39831.95it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 169809.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 15\n",
      "Maximum sequence length: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "src_data, src_lens, src_max_len = padding(src_data)\n",
    "trg_data, trg_lens, trg_max_len = padding(trg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dramatic-small",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 15])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 22])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# B: batch size\n",
    "# S_L : source maximum sequence length\n",
    "# T_L : target maximum sequence length\n",
    "\n",
    "# 전체를 하나의 배치로 \n",
    "\n",
    "src_batch = torch.LongTensor(src_data) # (B, S_L)\n",
    "src_batch_lens = torch.LongTensor(src_lens) # (B)\n",
    "trg_batch = torch.LongTensor(trg_data) # (B, T_L)\n",
    "trg_batch_lens = torch.LongTensor(trg_lens) # (B)\n",
    "\n",
    "print(src_batch.size())\n",
    "print(src_batch_lens.size())\n",
    "print(trg_batch.size())\n",
    "print(trg_batch_lens.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-majority",
   "metadata": {},
   "source": [
    "PackedSequence 사용을 위해 source data를 기준으로 정렬합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "willing-license",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99,  5],\n",
      "        [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93,  0,  0,  0,  0],\n",
      "        [63, 39,  5, 35, 67, 56, 68, 89, 55, 66,  0,  0,  0,  0,  0],\n",
      "        [ 3, 77, 56, 26,  3, 55, 12, 36, 31,  0,  0,  0,  0,  0,  0],\n",
      "        [29,  3, 52, 74, 73, 51, 39, 75, 19,  0,  0,  0,  0,  0,  0],\n",
      "        [58, 20, 65, 46, 26, 10, 76, 44,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [75, 34, 17,  3, 86, 88,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [12, 40, 69, 39, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [58, 17,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([15, 11, 10,  9,  9,  8,  6,  5,  3,  1])\n",
      "tensor([[ 1, 37, 14, 49, 24, 93, 37, 54, 51, 39, 84,  2,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18,  2,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 20, 70, 14,  6, 58, 90, 30, 17, 91, 18, 90,  2,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 75, 13, 22, 77, 89, 21, 13, 86, 95,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1,  8, 85, 87, 77, 47, 21, 23, 98, 83,  4, 47, 97, 40, 43, 70,  8, 65,\n",
      "         71, 69, 88,  2],\n",
      "        [ 1, 79, 14, 91, 41, 32, 79, 88, 34,  8, 68, 32, 77, 58,  7,  9, 87,  2,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 16, 98, 68, 57, 55, 46, 66, 85, 18,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 37, 93, 98, 13, 45, 28, 89, 72, 70,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 85,  8, 50, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 47, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0]])\n",
      "tensor([12, 14, 13, 11, 22, 18, 11, 11,  6,  4])\n"
     ]
    }
   ],
   "source": [
    "src_batch_lens, sorted_idx = src_batch_lens.sort(descending=True)\n",
    "src_batch = src_batch[sorted_idx]\n",
    "trg_batch = trg_batch[sorted_idx]\n",
    "trg_batch_lens = trg_batch_lens[sorted_idx]\n",
    "\n",
    "# tensor.sort() : values, index 두 개 출력\n",
    "\n",
    "print(src_batch)\n",
    "print(src_batch_lens)\n",
    "print(trg_batch)\n",
    "print(trg_batch_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-climb",
   "metadata": {},
   "source": [
    "## Encoder 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surface-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "num_dirs = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-suspension",
   "metadata": {},
   "source": [
    "Bidirectional GRU를 이용한 Encoder\n",
    "* `self.embedding` : word embedding layer\n",
    "* `self.gru` : encoder 역할을 하는 Bi-GRU\n",
    "* `self.linear` : 양/단방향 concat 된 hidden state 를 decoder 의 hidden size 에 맞게 linear transformation  \n",
    "(decoder 는 단방향이기 때문에 bidirectional 을 거친 층을 맞춰주기 위해 linear 층 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "guilty-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size = embedding_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            bidirectional = True if num_dirs > 1 else False,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        self.linear = nn.Linear(num_dirs * hidden_size , hidden_size)\n",
    "        \n",
    "        # forward 순서\n",
    "        # 1. embedding 후 transpose 후 학습 할 수 있게 packing\n",
    "        # 2. encoder gru 통과 : input, hidden_0 (여기서는 한 층이나, 본래 단어 단위로 gru 층마다 넣어준다.)\n",
    "        # 3. un_packing (to tensor)\n",
    "        # 4. decoder 주입용 hidden vector 추출 : bidirectional 이므로 마지막 벡터 -2, -1(양방향)\n",
    "          # bi : forward 방향 gru hidden , backward 방향 gru hidden\n",
    "        # 5. 두 정보를 담고 있는 hidden vectors 들을 하나로 압축 : linear 선형 변환\n",
    "        \n",
    "    def forward(self, batch, batch_lens):\n",
    "        # batch : (B, S_L), batch_lens : (B)\n",
    "        # d_w : word embedding size\n",
    "        batch_emb = self.embedding(batch) #(B, S_L, d_w)\n",
    "        batch_emb = batch_emb.transpose(0,1) # (S_L, B, d_w)\n",
    "        \n",
    "        packed_input = pack_padded_sequence(batch_emb, batch_lens) \n",
    "        # batch_lens = src_batch_lens\n",
    "        # tensor([15, 11, 10,  9,  9,  8,  6,  5,  3,  1])\n",
    "        h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))\n",
    "        # (num_layers*num_dirs, B, d_h) = (4, B, d_h)\n",
    "        # hidden vector 사이즈와 동일한 hidden vector 초기값\n",
    "        packed_outputs, h_n = self.gru(packed_input, h_0)\n",
    "        # h_n : (4, B, d_h)\n",
    "        outputs = pad_packed_sequence(packed_outputs)[0]\n",
    "        # outputs : (S_L, B, 2d_h)\n",
    "        \n",
    "        forward_hidden = h_n[-2, :, :]\n",
    "        backward_hidden = h_n[-1, :, :]\n",
    "        hidden = self.linear(torch.cat((forward_hidden, backward_hidden), dim=-1)).unsqueeze(0)\n",
    "        # (1, B, d_h)\n",
    "        \n",
    "        return outputs, hidden\n",
    "        # 여기서는 hidden state vector 만 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unknown-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-touch",
   "metadata": {},
   "source": [
    "## Decoder 구현\n",
    "\n",
    "동일한 설정의 Bi-GRU 로 만든 Decoder 입니다.\n",
    "* `self.embedding` : word embedding layer\n",
    "* `self.gru` : decoder 역할을 하는 Bi_GRU\n",
    "* `self.output_layer` : decoder 에서 나온 hidden state 를 `vocab_size` 로 linear transformation 하는 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "applied-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(\n",
    "             input_size = embedding_size,\n",
    "             hidden_size = hidden_size\n",
    "        )\n",
    "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, batch, hidden): # batch: (B), hidden: (1, B, d_h)\n",
    "        batch_emb = self.embedding(batch) # (B, d_w)\n",
    "        batch_emb = batch_emb.unsqueeze(0) # (1, B, d_w)\n",
    "        \n",
    "        outputs, hidden = self.gru(batch_emb, hidden)\n",
    "        # outputs : (1, B, 2d_h), hidden : (1, B, d_h)\n",
    "        \n",
    "        # V : vocab size\n",
    "        outputs = self.output_layer(outputs) # (1,B,V)\n",
    "        return outputs.squeeze(0), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "likely-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-bathroom",
   "metadata": {},
   "source": [
    "# Seq2Seq 모델 구축\n",
    "\n",
    "생성한 encoder 와 decoder 를 합쳐 Seq2Seq 모델을 구축합니다.\n",
    "* `self.encoder` : encoder\n",
    "* `self.decoder` : decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rational-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src_batch, src_batch_lens, trg_batch, teacher_forcing_prob=0.5):\n",
    "        # src_batch : (B, S_L)\n",
    "        # src_batch_lens : (B)\n",
    "        # trg_batdh : (B, T_L)\n",
    "        _, hidden = self.encoder(src_batch, src_batch_lens)\n",
    "        # hidden : (1, B, d_h)\n",
    "        \n",
    "        input_ids = trg_batch[:, 0] # (B) \n",
    "        # decoder 에서 한단어씩 생성하기 때문에, 첫단어를 주입\n",
    "        batch_size = src_batch.shape[0]\n",
    "        outputs = torch.zeros(trg_max_len, batch_size, vocab_size)\n",
    "        # (T_L, B, V)\n",
    "        \n",
    "        for t in range(1, trg_max_len):\n",
    "            decoder_outputs, hidden = self.decoder(input_ids, hidden)\n",
    "            # decoder_outputs : (B, V), hidden : (1, B, d_H)\n",
    "            \n",
    "            outputs[t] = decoder_outputs\n",
    "            _, top_ids = torch.max(decoder_outputs, dim=-1)\n",
    "            # top_ids : (B)\n",
    "\n",
    "            input_ids = trg_batch[:, t] if random.random() > teacher_forcing_prob else top_ids\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beneficial-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-sleeping",
   "metadata": {},
   "source": [
    "## 모델 사용해보기\n",
    "\n",
    "학습 과정이라고 가정하고 모델에 input 을 넣어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "amber-maximum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0986, -0.1136,  0.0275,  ..., -0.0260, -0.0677,  0.0501],\n",
      "         [ 0.0640, -0.1818, -0.0187,  ..., -0.0528, -0.0444,  0.0319],\n",
      "         [ 0.0767, -0.1089, -0.0008,  ...,  0.0202, -0.0889,  0.0550],\n",
      "         ...,\n",
      "         [ 0.0518, -0.1582, -0.0165,  ..., -0.0586, -0.0740,  0.0365],\n",
      "         [ 0.0699, -0.1259,  0.0130,  ..., -0.0063, -0.0546,  0.0759],\n",
      "         [ 0.0817, -0.1376, -0.0119,  ..., -0.0361, -0.0526,  0.0731]],\n",
      "\n",
      "        [[ 0.0736, -0.1202,  0.0748,  ...,  0.0635, -0.0899, -0.2654],\n",
      "         [-0.0754, -0.1762,  0.0029,  ..., -0.0633,  0.1265, -0.0327],\n",
      "         [-0.0129, -0.0157,  0.0676,  ..., -0.0143, -0.2319, -0.0660],\n",
      "         ...,\n",
      "         [ 0.0476, -0.1470,  0.0638,  ...,  0.0595, -0.0902, -0.2667],\n",
      "         [-0.0859, -0.1570,  0.0491,  ...,  0.0547, -0.2218, -0.0918],\n",
      "         [-0.1377, -0.0508, -0.0725,  ..., -0.0079, -0.1209,  0.0124]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0207, -0.0806, -0.1127,  ..., -0.0420, -0.2493,  0.1025],\n",
      "         [ 0.0837, -0.1968, -0.1091,  ..., -0.1457, -0.2176,  0.1020],\n",
      "         [-0.1065, -0.1397, -0.0694,  ..., -0.1047, -0.1791,  0.2324],\n",
      "         ...,\n",
      "         [-0.0735, -0.0027, -0.0518,  ..., -0.0276, -0.2520,  0.0622],\n",
      "         [ 0.0617, -0.1980, -0.1112,  ..., -0.1176, -0.2214,  0.1141],\n",
      "         [-0.0385, -0.0225,  0.0253,  ..., -0.1601, -0.1488,  0.1688]],\n",
      "\n",
      "        [[ 0.0413, -0.2566, -0.2464,  ...,  0.0483, -0.2352,  0.1456],\n",
      "         [ 0.0653, -0.0825, -0.0870,  ..., -0.0496, -0.0355,  0.0201],\n",
      "         [-0.1848, -0.2042, -0.1771,  ..., -0.0235, -0.0833,  0.2696],\n",
      "         ...,\n",
      "         [ 0.0188, -0.2088, -0.2168,  ...,  0.0620, -0.2322,  0.1259],\n",
      "         [ 0.1052, -0.3133, -0.2463,  ...,  0.0018, -0.2045,  0.1685],\n",
      "         [-0.1604, -0.1381, -0.1360,  ..., -0.0515, -0.0945,  0.2322]],\n",
      "\n",
      "        [[ 0.0653, -0.1625, -0.1199,  ..., -0.0466, -0.2453,  0.1258],\n",
      "         [ 0.0715, -0.0439, -0.0319,  ..., -0.0554, -0.1526,  0.0773],\n",
      "         [-0.0824, -0.1248, -0.0467,  ..., -0.1238, -0.1736,  0.2298],\n",
      "         ...,\n",
      "         [ 0.0565, -0.1327, -0.1049,  ..., -0.0338, -0.2477,  0.1169],\n",
      "         [ 0.1029, -0.1920, -0.1193,  ..., -0.0754, -0.2255,  0.1411],\n",
      "         [-0.0743, -0.0838, -0.0286,  ..., -0.1408, -0.1827,  0.2110]]],\n",
      "       grad_fn=<CopySlices>)\n",
      "torch.Size([22, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "outputs = seq2seq(src_batch, src_batch_lens, trg_batch)\n",
    "\n",
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-lunch",
   "metadata": {},
   "source": [
    "Language Modeling 에 대한 loss 계산을 위해 shift 한 target 과 비교합니다.\n",
    "\n",
    "![](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "precious-intermediate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6085, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "preds = outputs[1:, :, :].transpose(0,1) # (B, T_L-1, V)\n",
    "loss = loss_function(preds.contiguous().view(-1, vocab_size), \n",
    "                     trg_batch[:,1:].contiguous().view(-1, 1).squeeze(1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-brooks",
   "metadata": {},
   "source": [
    "실제 inference 에선 teacher forcing 없이 이전 결과만을 가지고 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "together-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sent = [4, 10, 88, 46, 72, 34, 14, 51]\n",
    "src_len = len(src_sent)\n",
    "\n",
    "src_batch = torch.LongTensor(src_sent).unsqueeze(0) # (1, L)\n",
    "src_batch_lens = torch.LongTensor([src_len]) # (1)\n",
    "\n",
    "_, hidden = seq2seq.encoder(src_batch, src_batch_lens) # hidden : (1, 1, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "verified-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = torch.LongTensor([sos_id]) # (1)\n",
    "output = []\n",
    "\n",
    "for t in range(1, trg_max_len):\n",
    "    decoder_output, hidden = seq2seq.decoder(input_id, hidden)  # decoder_output: (1, V), hidden: (1, 1, d_h)\n",
    "\n",
    "    _, top_id = torch.max(decoder_output, dim=-1)  # top_ids: (1)\n",
    "\n",
    "    if top_id == eos_id:\n",
    "        break\n",
    "    else:\n",
    "        output += top_id.tolist()\n",
    "        input_id = top_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "favorite-surfing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 3, 64, 41, 23, 3, 66, 66, 66, 71, 80, 92, 23, 9, 14, 76, 76, 30, 76, 30, 58]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-champagne",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
